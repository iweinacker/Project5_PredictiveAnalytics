{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "*   Fit and evaluate a regression model to predict SalePrice for the houses of the client\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/cleaned/HousePrediction.csv\n",
    "* Instructions on which variables to use for data cleaning and feature engineering. They are found in their respective notebooks.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* ML pipeline to predict tenure\n",
    "* labels map\n",
    "* Feature Importance Plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Project5_PredictiveAnalytics/jupyter_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Project5_PredictiveAnalytics'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXKlJFX0iuM5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xk7DU_ekbtX8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>...</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8450</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9600</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11250</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0           No         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "\n",
       "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
       "0        150         548          RFn       2003.0  ...     8450        65.0   \n",
       "1        284         460          RFn       1976.0  ...     9600        80.0   \n",
       "2        434         608          RFn       2001.0  ...    11250        68.0   \n",
       "\n",
       "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
       "0       196.0           61            5            7          856       2003   \n",
       "1         0.0            0            8            6         1262       1976   \n",
       "2       162.0           42            5            7          920       2001   \n",
       "\n",
       "   YearRemodAdd  SalePrice  \n",
       "0          2003     208500  \n",
       "1          1976     181500  \n",
       "2          2002     223500  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/HousePrediction.csv\")\n",
    "      .drop(labels=['EnclosedPorch', 'WoodDeckSF'], axis=1)\n",
    "      # variables we will not need for this project\n",
    "      )\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1stFlrSF          0\n",
       "2ndFlrSF         86\n",
       "BedroomAbvGr     99\n",
       "BsmtExposure      0\n",
       "BsmtFinSF1        0\n",
       "BsmtFinType1    114\n",
       "BsmtUnfSF         0\n",
       "GarageArea        0\n",
       "GarageFinish    162\n",
       "GarageYrBlt      81\n",
       "GrLivArea         0\n",
       "KitchenQual       0\n",
       "LotArea           0\n",
       "LotFrontage     259\n",
       "MasVnrArea        8\n",
       "OpenPorchSF       0\n",
       "OverallCond       0\n",
       "OverallQual       0\n",
       "TotalBsmtSF       0\n",
       "YearBuilt         0\n",
       "YearRemodAdd      0\n",
       "SalePrice         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import MeanMedianImputer\n",
    "imputer = MeanMedianImputer(imputation_method='median',\n",
    "                            variables=['2ndFlrSF' , 'BedroomAbvGr',\n",
    "                                       'GarageYrBlt', 'LotFrontage', 'MasVnrArea'])\n",
    "\n",
    "imputer.fit(df)\n",
    "df = imputer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "variables_method = ['GarageFinish', 'BsmtFinType1']\n",
    "\n",
    "imputer = CategoricalImputer(imputation_method='missing',\n",
    "                            variables=variables_method)\n",
    "imputer.fit(df)\n",
    "df = imputer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['2ndFlrSF', 'BedroomAbvGr', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea']\n",
    "df[cols] = df[cols].fillna(df[cols].mean())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BsmtFinType1', 'GarageFinish']\n",
    "df[cols] = df[cols].fillna('bfill')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import OneHotEncoder\n",
    "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
    "df_ohe = encoder.fit_transform(df)\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krjAk78Tbyhv"
   },
   "source": [
    "# MP Pipeline: Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6keis6ao8LA"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pandas import MultiIndex, Int64Index\n",
    "# Feature Engineering\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['GarageFinish', 'BsmtFinType1','BsmtExposure', 'KitchenQual', 'MasVnrArea'])),\n",
    "        \n",
    "\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "\n",
    "    ])\n",
    "   \n",
    "    return pipeline_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDmjjF3tHuCU"
   },
   "source": [
    "Custom Class for hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpTcVDtQ5RMc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD6B3CuhiDMT"
   },
   "source": [
    "## Split Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pFzP2iGiIk1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-15-sWUST6XX"
   },
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTFXq-ieogBj"
   },
   "source": [
    "### Use default hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZKV86gsPw8c"
   },
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGABtSoSLP9u"
   },
   "source": [
    "Do a hyperparameter optimisation search using default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_q-ru92GiBb"
   },
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7p56nXeoqWo"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mq4YlrmZooiw"
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pRUAeoG9lrZ"
   },
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2XCyOYkAYpZ"
   },
   "source": [
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyjC7ThFAYKY"
   },
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may consider more hyperparameters and spend more time in this step\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\": {\n",
    "        'model__n_estimators': [100,300],\n",
    "        'model__max_features': [5,10], \n",
    "        'model__max_depth': [5,10,15], \n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBy8thxqAlrd"
   },
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_4Ob7heAYM9"
   },
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtNJJpLEAzdP"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjauRLNHAYPr"
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWryh7BlA2df"
   },
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVWEmpSuA4C7"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_jvnR4sZ8km"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2my-LZFzZ-YD"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgWXlprwaAW-"
   },
   "source": [
    "Define the best regressor, based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OZ24jS0aAfP"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9uT2XmaKISR"
   },
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m6NUUa0KFQX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# after data cleaning and feature engineering, the features may have changes\n",
    "# how many data cleaning and feature engineering steps does your pipeline have?\n",
    "data_cleaning_feat_eng_steps = 2\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzNyQirSKJj6"
   },
   "source": [
    "## Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pBm_vx8BO9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV-W5nYyBPdk"
   },
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgBgrKJ5KFcX"
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ9tjLxEIn3h"
   },
   "source": [
    "# Regressor with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore potential values for PCA n_components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineOptimization(model=LinearRegression())\n",
    "pipeline_pca = Pipeline(pipeline.steps[:3])\n",
    "df_pca = pipeline_pca.fit_transform(df.drop(['SalePrice'], axis=1))\n",
    "\n",
    "print(df_pca.shape,'\\n', type(df_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA separately to the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 17\n",
    "\n",
    "\n",
    "def pca_components_analysis(df_pca, n_components):\n",
    "    pca = PCA(n_components=n_components).fit(df_pca)\n",
    "    x_PCA = pca.transform(df_pca)  # array with transformed PCA\n",
    "\n",
    "    ComponentsList = [\"Component \" + str(number)\n",
    "                      for number in range(n_components)]\n",
    "    dfExplVarRatio = pd.DataFrame(\n",
    "        data=np.round(100 * pca.explained_variance_ratio_, 3),\n",
    "        index=ComponentsList,\n",
    "        columns=['Explained Variance Ratio (%)'])\n",
    "\n",
    "    dfExplVarRatio['Accumulated Variance'] = dfExplVarRatio['Explained Variance Ratio (%)'].cumsum(\n",
    "    )\n",
    "\n",
    "    PercentageOfDataExplained = dfExplVarRatio['Explained Variance Ratio (%)'].sum(\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"* The {n_components} components explain {round(PercentageOfDataExplained,2)}% of the data \\n\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    sns.lineplot(data=dfExplVarRatio,  marker=\"o\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(np.arange(0, 110, 10))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pca_components_analysis(df_pca=df_pca, n_components=n_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 7\n",
    "pca_components_analysis(df_pca=df_pca, n_components=n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eaMf41ZBhBk"
   },
   "source": [
    "## Rewrite ML Pipeline for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfU562GBIsB1"
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['GarageFinish', 'BsmtFinType1','BsmtExposure', 'KitchenQual'])),\n",
    "        \n",
    "\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "\n",
    "\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        # PCA replace Feature Selection\n",
    "        (\"PCA\", PCA(n_components=7, random_state=0)),\n",
    "\n",
    "        (\"model\", model),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irUsq475Bn7N"
   },
   "source": [
    "## Grid Search CV â€“ Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LVF-KR_Bqum"
   },
   "source": [
    "### Use standard hyperparameters to find the most suitable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XmJNoUcJkKX"
   },
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq8td65fJkKY"
   },
   "source": [
    "Do a quick optimisation search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1BdqEB6JkKZ"
   },
   "outputs": [],
   "source": [
    "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ_Xj5oGJkKZ"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIC2csxKJkKZ"
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "383vOhJZBwza"
   },
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrcbiQHlB9QT"
   },
   "source": [
    "Define model and parameters for extensive search\n",
    "Change to improve the result\n",
    "increise amount of models to impruve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7t-fum6B9QU"
   },
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may consider more hyperparameters and spend more time in this step\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\": {\n",
    "        'model__max_features': [3,5,10], \n",
    "        'model__max_depth': [15,20,25,30], \n",
    "        'model__n_estimators': [300,400,500],\n",
    "        'model__min_samples_leaf': [1,2,4],\n",
    "        'model__bootstrap': [False, True],\n",
    "        'model__min_samples_split': [2,4,5],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvt-IOmHB9QU"
   },
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXbTwW1UB9QV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVUDzRSGB9QV"
   },
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZfOdh5kB9QW"
   },
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgoLo5C8B9QW"
   },
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3UGYjpcB9QW"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjY2MdBNB9QX"
   },
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uspihv71B9QX"
   },
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8HonhniB9QX"
   },
   "source": [
    "Define the best regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DC8U4skKB9QY"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKGmSgINCQwj"
   },
   "source": [
    "## Evaluate Regressor on Train and Tests Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78tt_ZkiJRdE"
   },
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test,\n",
    "                            best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBtppR73G1Yx"
   },
   "source": [
    "# Push files to the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShuJ5tYUC06o"
   },
   "source": [
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Modeling pipeline\n",
    "* label map\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vBpPvnaG5Mb"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_saleprice/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TvoMsi3DNw1"
   },
   "source": [
    "## Train Set: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJHmwyqgDOr1"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh6w6R7tDOvM"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB6pjmAcDOym"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ93HN6cDPBN"
   },
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVbS3OnRDYtJ"
   },
   "source": [
    "## Test Set: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbgF38n1DaPp"
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9lM0xDvDaVZ"
   },
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Jz66iMaDacI"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weYaJ4UxDake"
   },
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-XpkYAPFncu"
   },
   "source": [
    "## Modelling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLmFFWF6RGo6"
   },
   "source": [
    "ML pipeline for predicting SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQkr4rcrHDnn"
   },
   "outputs": [],
   "source": [
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrZPif2aHdyO"
   },
   "outputs": [],
   "source": [
    "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/best_regressor_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTJlYRC5Q2wJ"
   },
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SfLH05-Q2D8"
   },
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-Hc2H3dQ74Z"
   },
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh0SKfv_s-3V"
   },
   "source": [
    "Good job! Clear cell's outputs, push to the repo using git commands and move on to the next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Modeling and Evaluation - Predict Tenure.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
